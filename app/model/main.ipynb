{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL TEST AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import random\n",
    "# # import math \n",
    "# # import pandas as pd\n",
    "# # import tensorflow as tf\n",
    "# # import numpy as np\n",
    "# # import fastapi\n",
    "\n",
    "# # # change the url\n",
    "# # data_recipe = pd.read_excel('../data/recipe/all-recipe-cleaned.xlsx')\n",
    "# # base_ratings = pd.read_excel('../data/recipe/small_ratings.xlsx')  \n",
    "# # food_price = pd.read_excel('../data/recipe/harga-bahan-cleaned.xlsx')\n",
    " \n",
    "    \n",
    "# # # load the model  \n",
    "# # def load_model(): \n",
    "# #     # change the url (for load model use the API)\n",
    "# #     load_model = tf.keras.models.load_model(\"../model/RecomendationV2.h5\")\n",
    "# #     return load_model\n",
    "\n",
    "\n",
    "# # # load thee weight, X and bias\n",
    "# # def load_weights_X_bias():\n",
    "# #     # change the url\n",
    "# #     W = tf.Variable(pd.read_excel(\"../data/user_ratings/small-W-final.xlsx\", index_col=0)) \n",
    "# #     X  = tf.Variable(pd.read_excel(\"../data/user_ratings/small-X-final.xlsx\", index_col=0))\n",
    "# #     bias  = tf.Variable(pd.read_excel(\"../data/user_ratings/small-B-final.xlsx\", index_col=0)) \n",
    "# #     return W,X, bias\n",
    "\n",
    "# # # this function was created to get new user's ratings\n",
    "# # def get_new_user_ratings(recipe_dataset, base_ratings, user_country_references): \n",
    "# #     new_user_rating = np.zeros(base_ratings.shape[0])\n",
    "# #     rated_by_new_user_index = np.zeros(base_ratings.shape[0])\n",
    "# #     country_liked_selected = user_country_references\n",
    "# #     for j in country_liked_selected:\n",
    "# #         for i in range(len(recipe_dataset)): \n",
    "# #             if recipe_dataset['kategori'].iloc[i] in j:\n",
    "# #                 random_rate = np.random.randint(low = 3, high=6) \n",
    "# #                 rated_by_new_user_index[i] = int(i) \n",
    "# #                 new_user_rating[i] = random_rate\n",
    "# #     return new_user_rating, rated_by_new_user_index\n",
    "\n",
    "# # # this function  is to convet based ratings dataset to numpy array\n",
    "# # def based_ratings(based_ratings): \n",
    "# #     Y = []\n",
    "# #     temp = []\n",
    "# #     for i in range(len(based_ratings)): \n",
    "# #         for j in range(1, 201): \n",
    "# #             temp.append(based_ratings[f'user{j}'].iloc[i])\n",
    "# #         Y.append(temp)\n",
    "# #         temp = []\n",
    "# #     return Y\n",
    "\n",
    "# # # concat the new user's ratings and get the index\n",
    "# # def concat_based_new_user_ratings(): \n",
    "# #     # this function actually have user_country_references, CC team you can add the parameter with the configuration \n",
    "# #     get_based_ratings = based_ratings(base_ratings)\n",
    "# #     new_user_ratings, new_user_ratings_index = get_new_user_ratings(recipe_dataset = data_recipe, base_ratings = base_ratings, user_country_references =  [\"Indonesian'\", \"Thailand'\",  \"Korean'\"])\n",
    "# #     return np.c_[new_user_ratings, get_based_ratings], new_user_ratings_index\n",
    "\n",
    "# # # retrain the model to make sure the model can learn from new user's ratings\n",
    "# # def retrain():\n",
    "# #     user_weight,recipe_x, bias = load_weights_X_bias() \n",
    "# #     Y, new_user_ratings_index = concat_based_new_user_ratings()\n",
    "# #     model = load_model()\n",
    "# #     model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error', metrics = 'mse')\n",
    "# #     model.fit(x = np.matmul(recipe_x.numpy(), np.transpose(user_weight)) + bias.numpy(), y = Y, epochs=2)\n",
    "# #     new_user_prediction = model.predict(np.matmul(recipe_x.numpy(), np.transpose(user_weight)) + bias.numpy())[:, 0]\n",
    "# #     pred = tf.argsort(new_user_prediction, direction = 'DESCENDING')\n",
    "# #     return pred\n",
    "# # # give the final recomendation based on user preferences\n",
    "# # def final_recomendation(prediction, bahan_yang_disukai_param, bahan_yang_tidak_disukai_param, pantangan_makan_param, budget_param, jumlah_makan_sehari_param, jumlah_dewasa_param, jumlah_anak_param):\n",
    "# #     bahan_yang_disukai = bahan_yang_disukai_param\n",
    "# #     bahan_yang_tidak_disukai = bahan_yang_tidak_disukai_param\n",
    "# #     pantangan_makanan = pantangan_makan_param\n",
    "# #     budget = budget_param\n",
    "# #     jumlah_makan_sehari = jumlah_makan_sehari_param\n",
    "# #     jumlah_dewasa = jumlah_dewasa_param\n",
    "# #     jumlah_anak = jumlah_anak_param\n",
    "# #     all_recomendation = []\n",
    "# #     # change the url\n",
    "# #     data_bahan = data_recipe['nama_bahan']   \n",
    "# #     # change the url\n",
    "# #     data_harga_bahan = food_price\n",
    "# #     recipe_dataset = data_recipe\n",
    "# #     for i in range(len(prediction)):   \n",
    "# #         j = prediction[i]\n",
    "# #         all_recomendation.append(int(j))\n",
    "\n",
    "   \n",
    "# #     recipe_filter_by_bahan = []\n",
    "# #     for i in range(len(all_recomendation)):\n",
    "# #         for j in range(len(bahan_yang_disukai)): \n",
    "# #             if bahan_yang_disukai[j] in data_bahan[i].replace(\"'\", '').split(\",\") or bahan_yang_disukai[j].lower() in data_bahan[i].replace(\"'\", '').split(\",\"): \n",
    "# #                 if (bahan_yang_tidak_disukai not in data_bahan[i].replace(\"'\", '').split(\",\") or bahan_yang_tidak_disukai.lower() not in data_bahan[i].replace(\"'\", '').split(\",\")) and pantangan_makanan not in data_bahan[i].replace(\"'\", '').split(\",\"): \n",
    "# #                     recipe_filter_by_bahan.append(int(i))\n",
    "\n",
    "# #     for j in recipe_filter_by_bahan:\n",
    "# #         for i in range(1, len(recipe_filter_by_bahan)): \n",
    "# #             if int(float(recipe_dataset['kandungan_nutrisi'].iloc[int(recipe_filter_by_bahan[i])].replace(\"'\", \"\").replace(\"'\", \"\").strip().split(',')[1])) > int(float(recipe_dataset['kandungan_nutrisi'].iloc[int(recipe_filter_by_bahan[i - 1])].replace(\"'\", \"\").replace(\"'\", \"\").strip().split(',')[1])): \n",
    "# #                 temp = recipe_filter_by_bahan[i-1]\n",
    "# #                 recipe_filter_by_bahan[i -1] = recipe_filter_by_bahan[i]\n",
    "# #                 recipe_filter_by_bahan[i] = temp\n",
    "# #     get_harga_bahan = []\n",
    "# #     get_bahan_recipe = []\n",
    "# #     for i in recipe_filter_by_bahan:\n",
    "# #         get_bahan_recipe.append(recipe_dataset['nama_bahan'].iloc[i].replace(\"'\", \"\").replace(\"'\", \"\").split(','))\n",
    "# #     all_satuan = []\n",
    "\n",
    "# #     for i in range(len(recipe_filter_by_bahan)): \n",
    "# #         temp  = recipe_dataset['satuan'].iloc[i].replace(\"'\", \"\").split(\",\")\n",
    "# #         all_satuan.append(temp)\n",
    "\n",
    "# #     for i in range(len(get_bahan_recipe)): \n",
    "# #         total = 0\n",
    "# #         for j in range(len(get_bahan_recipe[i])): \n",
    "# #             for k in range(len(data_harga_bahan)): \n",
    "# #                 if str(data_harga_bahan['nama_bahan'].iloc[k]).replace(\" \", \"\") == get_bahan_recipe[i][j].replace(\" \", \"\") :\n",
    "# #                     if j < len(all_satuan[i]):\n",
    "# #                         if all_satuan[i][j] == \"ons\":   \n",
    "# #                             total += ((data_harga_bahan['harga'].iloc[k]) / 4)\n",
    "# #                         elif str(all_satuan[i][j]).replace(\" \", \"\") == 'sendokteh' or str(all_satuan[i][j]).replace(\" \", \"\") == 'sendokmakan':   \n",
    "# #                             total += ((data_harga_bahan['harga'].iloc[k]) / 10)\n",
    "# #                         elif str(all_satuan[i][j].replace(\" \", \"\")) == 'cangkir' or 'cangkir' in str(all_satuan[i][j].replace(\" \", \"\")):   \n",
    "# #                             total += ((data_harga_bahan['harga'].iloc[k]) / 2) \n",
    "# #                     else: \n",
    "# #                         total += (data_harga_bahan['harga'].iloc[k])\n",
    "# #         get_harga_bahan.append(total)\n",
    "\n",
    "\n",
    "# #     for i in range(len(get_harga_bahan)): \n",
    "# #         if get_harga_bahan[i] <= 50000: \n",
    "# #             continue\n",
    "# #         elif get_harga_bahan[i] <= 100000 and get_harga_bahan[i] >  50000: \n",
    "# #             get_harga_bahan[i] = get_harga_bahan[i] / 4\n",
    "# #         elif get_harga_bahan[i] > 100000 and get_harga_bahan[i] <= 200000: \n",
    "# #             get_harga_bahan[i] = get_harga_bahan[i] / 6\n",
    "# #         else: \n",
    "# #             get_harga_bahan[i] = get_harga_bahan[i] / 8\n",
    "        \n",
    "# #     final_recomend = []\n",
    "# #     for i in range(len(get_harga_bahan)): \n",
    "# #         temp = []\n",
    "# #         total  = 0\n",
    "# #         max_jump = int(len(get_harga_bahan) / (7 * jumlah_makan_sehari)) \n",
    "# #         jump = random.randint(a=1, b= max_jump)\n",
    "# #         for j in range(i, len(get_harga_bahan) - jump): \n",
    "# #             if int(total) <= int(budget):\n",
    "# #                 total += (get_harga_bahan[j + jump] * (jumlah_dewasa + math.ceil(0.5 * jumlah_anak)))\n",
    "# #                 temp.append(recipe_filter_by_bahan[j + jump])\n",
    "# #             else: \n",
    "# #                   temp = []\n",
    "            \n",
    "# #         if len(temp) >= 7 * jumlah_makan_sehari: \n",
    "# #             if temp not in final_recomend:\n",
    "# #                 final_recomend.append(temp)\n",
    "    \n",
    "\n",
    "# #     # delete this if neccesary \n",
    "# #     week = 1\n",
    "# #     for i in final_recomend: \n",
    "# #         print(f'mingggu {week}')\n",
    "# #         for j in i: \n",
    "# #             print(recipe_dataset['nama_makanan'].iloc[j])\n",
    "# #         print(\"=================================================\")\n",
    "# #         print(\"=================================================\")\n",
    "# #         week += 1\n",
    "\n",
    "# #     return final_recomend\n",
    "\n",
    "# # def get_recommender(bahan_yang_disukai = ['Nasi', 'Bayam', 'Sapi', 'Babi'], bahan_yang_tidak_disukai = 'Keju' , pantangan_makan = '', budget = 2000000, jumlah_makan_sehari = 3, jumlah_dewasa = 2, jumlah_anak  = 2): \n",
    "# #     pred = retrain()\n",
    "# #     all = final_recomendation(prediction=pred, bahan_yang_disukai_param= bahan_yang_disukai, bahan_yang_tidak_disukai_param=bahan_yang_tidak_disukai, pantangan_makan_param= pantangan_makan, budget_param= budget, jumlah_makan_sehari_param=jumlah_makan_sehari, jumlah_anak_param = jumlah_anak,jumlah_dewasa_param=jumlah_dewasa)\n",
    "# #     return all \n",
    "\n",
    "# # # print(get_recommender())\n",
    "# # # pred = retrain()\n",
    "# # # all = final_recomendation(prediction=pred, bahan_yang_disukai_param=['Nasi', 'Bayam', 'Sapi', 'Babi'], bahan_yang_tidak_disukai_param='Keju', pantangan_makan_param='', budget_param=2000000, jumlah_makan_sehari_param=3, jumlah_anak_param = 2,jumlah_dewasa_param=2)\n",
    "\n",
    "# import random\n",
    "# import math \n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# import fastapi\n",
    "\n",
    "\n",
    "# # version of model\n",
    "# __version__ = \"2.0.0\"\n",
    "# # change the url\n",
    "# data_recipe = pd.read_excel('./data/recipe/all-recipe-cleaned.xlsx')\n",
    "# base_ratings = pd.read_excel('./data/recipe/small_ratings.xlsx')  \n",
    "# food_price = pd.read_excel('./data/recipe/harga-bahan-cleaned.xlsx')\n",
    " \n",
    "    \n",
    "# # load the model  \n",
    "# def load_model(): \n",
    "#     # change the url (for load model use the API)\n",
    "#     load_model = tf.keras.models.load_model(\"../model/RecomendationV2.h5\")\n",
    "#     return load_model\n",
    "\n",
    "\n",
    "# # load thee weight, X and bias\n",
    "# def load_weights_X_bias():\n",
    "#     # change the url\n",
    "#     W = tf.Variable(pd.read_excel(\"./data/user_ratings/small-W-final.xlsx\", index_col=0)) \n",
    "#     X  = tf.Variable(pd.read_excel(\"./data/user_ratings/small-X-final.xlsx\", index_col=0))\n",
    "#     bias  = tf.Variable(pd.read_excel(\"./data/user_ratings/small-B-final.xlsx\", index_col=0)) \n",
    "#     return W,X, bias\n",
    "\n",
    "# # this function was created to get new user's ratings\n",
    "# def get_new_user_ratings(recipe_dataset, base_ratings, user_country_references): \n",
    "#     new_user_rating = np.zeros(base_ratings.shape[0])\n",
    "#     rated_by_new_user_index = np.zeros(base_ratings.shape[0])\n",
    "#     country_liked_selected = user_country_references\n",
    "#     for j in country_liked_selected:\n",
    "#         for i in range(len(recipe_dataset)): \n",
    "#             if recipe_dataset['kategori'].iloc[i] in j:\n",
    "#                 random_rate = np.random.randint(low = 3, high=6) \n",
    "#                 rated_by_new_user_index[i] = int(i) \n",
    "#                 new_user_rating[i] = random_rate\n",
    "#     return new_user_rating, rated_by_new_user_index\n",
    "\n",
    "# # this function  is to convet based ratings dataset to numpy array\n",
    "# def based_ratings(based_ratings): \n",
    "#     Y = []\n",
    "#     temp = []\n",
    "#     for i in range(len(based_ratings)): \n",
    "#         for j in range(1, 201): \n",
    "#             temp.append(based_ratings[f'user{j}'].iloc[i])\n",
    "#         Y.append(temp)\n",
    "#         temp = []\n",
    "#     return Y\n",
    "\n",
    "# # concat the new user's ratings and get the index\n",
    "# def concat_based_new_user_ratings(): \n",
    "#     # this function actually have user_country_references, CC team you can add the parameter with the configuration \n",
    "#     get_based_ratings = based_ratings(base_ratings)\n",
    "#     new_user_ratings, new_user_ratings_index = get_new_user_ratings(recipe_dataset = data_recipe, base_ratings = base_ratings, user_country_references =  [\"Indonesian'\", \"Thailand'\",  \"Korean'\"])\n",
    "#     return np.c_[new_user_ratings, get_based_ratings], new_user_ratings_index\n",
    "\n",
    "# # retrain the model to make sure the model can learn from new user's ratings\n",
    "# def retrain():\n",
    "#     user_weight,recipe_x, bias = load_weights_X_bias() \n",
    "#     Y, new_user_ratings_index = concat_based_new_user_ratings()\n",
    "#     model = load_model()\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error', metrics = 'mse')\n",
    "#     model.fit(x = np.matmul(recipe_x.numpy(), np.transpose(user_weight)) + bias.numpy(), y = Y, epochs=2)\n",
    "#     new_user_prediction = model.predict(np.matmul(recipe_x.numpy(), np.transpose(user_weight)) + bias.numpy())[:, 0]\n",
    "#     pred = tf.argsort(new_user_prediction, direction = 'DESCENDING')\n",
    "#     return pred\n",
    "# # give the final recomendation based on user preferences\n",
    "# def final_recomendation(prediction, bahan_yang_disukai_param, bahan_yang_tidak_disukai_param, pantangan_makan_param, budget_param, jumlah_makan_sehari_param, jumlah_dewasa_param, jumlah_anak_param):\n",
    "#     bahan_yang_disukai = bahan_yang_disukai_param\n",
    "#     bahan_yang_tidak_disukai = bahan_yang_tidak_disukai_param\n",
    "#     pantangan_makanan = pantangan_makan_param\n",
    "#     budget = budget_param\n",
    "#     jumlah_makan_sehari = jumlah_makan_sehari_param\n",
    "#     jumlah_dewasa = jumlah_dewasa_param\n",
    "#     jumlah_anak = jumlah_anak_param\n",
    "#     all_recomendation = []\n",
    "#     # change the url\n",
    "#     data_bahan = data_recipe['nama_bahan']   \n",
    "#     # change the url\n",
    "#     data_harga_bahan = food_price\n",
    "#     recipe_dataset = data_recipe\n",
    "#     for i in range(len(prediction)):   \n",
    "#         j = prediction[i]\n",
    "#         all_recomendation.append(int(j))\n",
    "\n",
    "   \n",
    "#     recipe_filter_by_bahan = []\n",
    "#     for i in range(len(all_recomendation)):\n",
    "#         for j in range(len(bahan_yang_disukai)): \n",
    "#             if bahan_yang_disukai[j] in data_bahan[i].replace(\"'\", '').split(\",\") or bahan_yang_disukai[j].lower() in data_bahan[i].replace(\"'\", '').split(\",\"): \n",
    "#                 if (bahan_yang_tidak_disukai not in data_bahan[i].replace(\"'\", '').split(\",\") or bahan_yang_tidak_disukai.lower() not in data_bahan[i].replace(\"'\", '').split(\",\")) and pantangan_makanan not in data_bahan[i].replace(\"'\", '').split(\",\"): \n",
    "#                     recipe_filter_by_bahan.append(int(i))\n",
    "\n",
    "#     for j in recipe_filter_by_bahan:\n",
    "#         for i in range(1, len(recipe_filter_by_bahan)): \n",
    "#             if int(float(recipe_dataset['kandungan_nutrisi'].iloc[int(recipe_filter_by_bahan[i])].replace(\"'\", \"\").replace(\"'\", \"\").strip().split(',')[1])) > int(float(recipe_dataset['kandungan_nutrisi'].iloc[int(recipe_filter_by_bahan[i - 1])].replace(\"'\", \"\").replace(\"'\", \"\").strip().split(',')[1])): \n",
    "#                 temp = recipe_filter_by_bahan[i-1]\n",
    "#                 recipe_filter_by_bahan[i -1] = recipe_filter_by_bahan[i]\n",
    "#                 recipe_filter_by_bahan[i] = temp\n",
    "#     get_harga_bahan = []\n",
    "#     get_bahan_recipe = []\n",
    "#     for i in recipe_filter_by_bahan:\n",
    "#         get_bahan_recipe.append(recipe_dataset['nama_bahan'].iloc[i].replace(\"'\", \"\").replace(\"'\", \"\").split(','))\n",
    "#     all_satuan = []\n",
    "\n",
    "#     for i in range(len(recipe_filter_by_bahan)): \n",
    "#         temp  = recipe_dataset['satuan'].iloc[i].replace(\"'\", \"\").split(\",\")\n",
    "#         all_satuan.append(temp)\n",
    "\n",
    "#     for i in range(len(get_bahan_recipe)): \n",
    "#         total = 0\n",
    "#         for j in range(len(get_bahan_recipe[i])): \n",
    "#             for k in range(len(data_harga_bahan)): \n",
    "#                 if str(data_harga_bahan['nama_bahan'].iloc[k]).replace(\" \", \"\") == get_bahan_recipe[i][j].replace(\" \", \"\") :\n",
    "#                     if j < len(all_satuan[i]):\n",
    "#                         if all_satuan[i][j] == \"ons\":   \n",
    "#                             total += ((data_harga_bahan['harga'].iloc[k]) / 4)\n",
    "#                         elif str(all_satuan[i][j]).replace(\" \", \"\") == 'sendokteh' or str(all_satuan[i][j]).replace(\" \", \"\") == 'sendokmakan':   \n",
    "#                             total += ((data_harga_bahan['harga'].iloc[k]) / 10)\n",
    "#                         elif str(all_satuan[i][j].replace(\" \", \"\")) == 'cangkir' or 'cangkir' in str(all_satuan[i][j].replace(\" \", \"\")):   \n",
    "#                             total += ((data_harga_bahan['harga'].iloc[k]) / 2) \n",
    "#                     else: \n",
    "#                         total += (data_harga_bahan['harga'].iloc[k])\n",
    "#         get_harga_bahan.append(total)\n",
    "\n",
    "\n",
    "#     for i in range(len(get_harga_bahan)): \n",
    "#         if get_harga_bahan[i] <= 50000: \n",
    "#             continue\n",
    "#         elif get_harga_bahan[i] <= 100000 and get_harga_bahan[i] >  50000: \n",
    "#             get_harga_bahan[i] = get_harga_bahan[i] / 4\n",
    "#         elif get_harga_bahan[i] > 100000 and get_harga_bahan[i] <= 200000: \n",
    "#             get_harga_bahan[i] = get_harga_bahan[i] / 6\n",
    "#         else: \n",
    "#             get_harga_bahan[i] = get_harga_bahan[i] / 8\n",
    "        \n",
    "#     final_recomend = []\n",
    "#     for i in range(len(get_harga_bahan)): \n",
    "#         temp = []\n",
    "#         total  = 0\n",
    "#         max_jump = int(len(get_harga_bahan) / (7 * jumlah_makan_sehari)) \n",
    "#         jump = random.randint(a=1, b= max_jump)\n",
    "#         for j in range(i, len(get_harga_bahan) - jump): \n",
    "#             if int(total) <= int(budget):\n",
    "#                 total += (get_harga_bahan[j + jump] * (jumlah_dewasa + math.ceil(0.5 * jumlah_anak)))\n",
    "#                 temp.append(recipe_filter_by_bahan[j + jump])\n",
    "#             else: \n",
    "#                   temp = []\n",
    "            \n",
    "#         if len(temp) >= 7 * jumlah_makan_sehari: \n",
    "#             if temp not in final_recomend:\n",
    "#                 final_recomend.append(temp)\n",
    "    \n",
    "\n",
    "#     # delete this if neccesary \n",
    "#     week = 1\n",
    "#     for i in final_recomend: \n",
    "#         print(f'mingggu {week}')\n",
    "#         for j in i: \n",
    "#             print(recipe_dataset['nama_makanan'].iloc[j])\n",
    "#         print(\"=================================================\")\n",
    "#         print(\"=================================================\")\n",
    "#         week += 1\n",
    "\n",
    "#     return final_recomend\n",
    "\n",
    "# def get_recommender(bahan_yang_disukai = ['Nasi', 'Bayam', 'Sapi'], bahan_yang_tidak_disukai = 'Keju' , pantangan_makan = ['Babi', 'Ayam'], budget = 2000000, jumlah_makan_sehari = 3, jumlah_dewasa = 2, jumlah_anak  = 2): \n",
    "#     pred = retrain()\n",
    "#     all = final_recomendation(prediction=pred, bahan_yang_disukai_param= bahan_yang_disukai, bahan_yang_tidak_disukai_param=bahan_yang_tidak_disukai, pantangan_makan_param= pantangan_makan, budget_param= budget, jumlah_makan_sehari_param=jumlah_makan_sehari, jumlah_anak_param = jumlah_anak,jumlah_dewasa_param=jumlah_dewasa)\n",
    "#     return all \n",
    "\n",
    "# a = get_recommender()\n",
    "# # pred = retrain()\n",
    "# # all = final_recomendation(prediction=pred, bahan_yang_disukai_param=['Nasi', 'Bayam', 'Sapi', 'Babi'], bahan_yang_tidak_disukai_param='Keju', pantangan_makan_param='', budget_param=2000000, jumlah_makan_sehari_param=3, jumlah_anak_param = 2,jumlah_dewasa_param=2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import math \n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# import fastapi\n",
    "# import sqlalchemy\n",
    "\n",
    "# def connect_with_connector() -> sqlalchemy.engine.base.Engine:\n",
    "#     \"\"\"\n",
    "#     Initializes a connection pool for a Cloud SQL instance of SQL Server.\n",
    "\n",
    "#     Uses the Cloud SQL Python Connector package.\n",
    "#     \"\"\"\n",
    "#     # Note: Saving credentials in environment variables is convenient, but not\n",
    "#     # secure - consider a more secure solution such as\n",
    "#     # Cloud Secret Manager (https://cloud.google.com/secret-manager) to help\n",
    "#     # keep secrets safe.\n",
    "\n",
    "#     instance_connection_name = os.environ[\n",
    "#         \"dapurly:asia-southeast2:dapurly-db\"\n",
    "#     ]  # e.g. 'project:region:instance'\n",
    "#     db_user = os.environ.get(\"dapurly-project\")  # e.g. 'my-db-user'\n",
    "#     db_pass = os.environ[\"12345\"]  # e.g. 'my-db-password'\n",
    "#     db_name = os.environ[\"dapurly-db\"]  # e.g. 'my-database'\n",
    "\n",
    "#     ip_type = IPTypes.PRIVATE if os.environ.get(\"34.128.103.197\") else IPTypes.PUBLIC\n",
    "\n",
    "#     connector = Connector(ip_type)\n",
    "\n",
    "#     connect_args = {}\n",
    "#     # If your SQL Server instance requires SSL, you need to download the CA\n",
    "#     # certificate for your instance and include cafile={path to downloaded\n",
    "#     # certificate} and validate_host=False. This is a workaround for a known issue.\n",
    "#     if os.environ.get(\"DB_ROOT_CERT\"):  # e.g. '/path/to/my/server-ca.pem'\n",
    "#         connect_args = {\n",
    "#             \"cafile\": os.environ[\"DB_ROOT_CERT\"],\n",
    "#             \"validate_host\": False,\n",
    "#         }\n",
    "\n",
    "#     def getconn() -> pytds.Connection:\n",
    "#         conn = connector.connect(\n",
    "#             instance_connection_name,\n",
    "#             \"pytds\",\n",
    "#             user=db_user,\n",
    "#             password=db_pass,\n",
    "#             db=db_name,\n",
    "#             **connect_args\n",
    "#         )\n",
    "#         return conn\n",
    "\n",
    "#     pool = sqlalchemy.create_engine(\n",
    "#         \"mssql+pytds://\",\n",
    "#         creator=getconn,\n",
    "#         # ...\n",
    "#     )\n",
    "#     return pool\n",
    "# # base_ratings = pd.read_sql('http://34.101.48.61/final-rating')  \n",
    "# # food_price = pd.read_sql('http://34.101.48.61/harga-bahan')\n",
    "# sql_query = \"SELECT * FROM recipe;\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import fastapi\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# version of model\n",
    "__version__ = \"2.0.0\"\n",
    "# change the url\n",
    "def get_data_template(table_name):\n",
    "    db_user = 'root'\n",
    "    db_password = '12345'\n",
    "    db_port = 3306\n",
    "    db_host = \"34.128.103.197\"\n",
    "    db_name = 'dapurly-db'\n",
    "\n",
    "    # Create the connection string\n",
    "    connection_string =  f'mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'\n",
    "\n",
    "    # Create the engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Write your SQL query\n",
    "    sql_query = text(f'SELECT * FROM `{table_name}`')\n",
    "\n",
    "    # Use pandas.read_sql() to read the query results into a DataFrame\n",
    "    # df = pd.read_sql_query(sql_query, con = engine)\n",
    "    with engine.connect().execution_options(stream_results=True) as connection:\n",
    "        result = connection.execute(sql_query)\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "        # df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "        # df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    return df\n",
    "# change the url        \n",
    "data_recipe = get_data_template(table_name=\"all-recipe\")\n",
    "base_ratings = get_data_template(table_name='user-ratings')  \n",
    "food_price = get_data_template(table_name='harga_clean')  \n",
    " \n",
    "    \n",
    "# load the model  \n",
    "def load_model(): \n",
    "    # change the url (for load model use the API)\n",
    "    load_model = tf.keras.models.load_model(\"./RecomendationV2.h5\")\n",
    "    return load_model\n",
    "\n",
    "\n",
    "# load thee weight, X and bias\n",
    "def load_weights_X_bias():\n",
    "    # change the url\n",
    "    W = tf.Variable(get_data_template(table_name='small-W-final')) \n",
    "    X  = tf.Variable(get_data_template(table_name='small-X-final'))\n",
    "    bias  = tf.Variable(get_data_template(table_name='small-B-final')) \n",
    "    return W,X, bias\n",
    "\n",
    "# this function was created to get new user's ratings\n",
    "def get_new_user_ratings(recipe_dataset, base_ratings, user_country_references): \n",
    "    new_user_rating = np.zeros(base_ratings.shape[0])\n",
    "    rated_by_new_user_index = np.zeros(base_ratings.shape[0])\n",
    "    country_liked_selected = user_country_references\n",
    "    for j in country_liked_selected:\n",
    "        for i in range(len(recipe_dataset)): \n",
    "            if recipe_dataset['kategori'].iloc[i] in j:\n",
    "                random_rate = np.random.randint(low = 3, high=6) /5\n",
    "                rated_by_new_user_index[i] = int(i) \n",
    "                new_user_rating[i] = random_rate\n",
    "    return new_user_rating, rated_by_new_user_index\n",
    "\n",
    "# this function  is to convet based ratings dataset to numpy array\n",
    "def based_ratings(based_ratings): \n",
    "    Y = []\n",
    "    temp = []\n",
    "    for i in range(len(based_ratings)): \n",
    "        for j in range(1, 200): \n",
    "            temp.append(based_ratings[f'user{j}'].iloc[i])\n",
    "        Y.append(temp)\n",
    "        temp = []\n",
    "    return Y\n",
    "\n",
    "# concat the new user's ratings and get the index\n",
    "def concat_based_new_user_ratings(user_country_references_param): \n",
    "    # this function actually have user_country_references, CC team you can add the parameter with the configuration \n",
    "    get_based_ratings = based_ratings(base_ratings)\n",
    "    new_user_ratings, new_user_ratings_index = get_new_user_ratings(recipe_dataset = data_recipe, base_ratings = base_ratings, user_country_references =  user_country_references_param)\n",
    "    Y_concat = np.array(np.c_[new_user_ratings, get_based_ratings])\n",
    "    return Y_concat\n",
    "    # Y_concat = np.concatenate((new_user_ratings, get_based_ratings), axis=1)\n",
    "    # Y_concat = Y_concat.flatten()\n",
    "    # return Y_concat\n",
    "\n",
    "\n",
    "# retrain the model to make sure the model can learn from new user's ratings\n",
    "def retrain(country_refrences):\n",
    "    user_weight,recipe_x, bias = load_weights_X_bias() \n",
    "    Y = concat_based_new_user_ratings(user_country_references_param=country_refrences)\n",
    "    model = load_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error', metrics = 'mse')\n",
    "    model.fit(x = np.matmul(recipe_x.numpy(), np.transpose(user_weight)) + bias.numpy(), y = Y, epochs=2)\n",
    "    new_user_prediction = model.predict(np.matmul(recipe_x.numpy(), np.transpose(user_weight)) + bias.numpy())[:, 0]\n",
    "    pred = tf.argsort(new_user_prediction, direction = 'DESCENDING')\n",
    "    return pred\n",
    "# give the final recomendation based on user preferences\n",
    "def final_recomendation(prediction, bahan_yang_disukai_param, bahan_yang_tidak_disukai_param, pantangan_makan_param, budget_param, jumlah_makan_sehari_param, jumlah_dewasa_param, jumlah_anak_param):\n",
    "    bahan_yang_disukai = bahan_yang_disukai_param\n",
    "    bahan_yang_tidak_disukai = bahan_yang_tidak_disukai_param\n",
    "    pantangan_makanan = pantangan_makan_param\n",
    "    budget = budget_param\n",
    "    jumlah_makan_sehari = jumlah_makan_sehari_param\n",
    "    jumlah_dewasa = jumlah_dewasa_param\n",
    "    jumlah_anak = jumlah_anak_param\n",
    "    all_recomendation = []\n",
    "    # change the url\n",
    "    data_bahan = data_recipe['nama_bahan']   \n",
    "    # change the url\n",
    "    data_harga_bahan = food_price\n",
    "    recipe_dataset = data_recipe\n",
    "    for i in range(len(prediction)):   \n",
    "        j = prediction[i]\n",
    "        all_recomendation.append(int(j))\n",
    "\n",
    "    recipe_filter_by_bahan = []\n",
    "    for i in range(len(all_recomendation)):\n",
    "        for j in range(len(bahan_yang_disukai)): \n",
    "            if bahan_yang_disukai[j] in data_bahan[i].replace(\"'\", '').split(\",\") or bahan_yang_disukai[j].lower() in data_bahan[i].replace(\"'\", '').split(\",\"): \n",
    "                if (bahan_yang_tidak_disukai not in data_bahan[i].replace(\"'\", '').split(\",\") or bahan_yang_tidak_disukai.lower() not in data_bahan[i].replace(\"'\", '').split(\",\")) and pantangan_makanan not in data_bahan[i].replace(\"'\", '').split(\",\"): \n",
    "                    recipe_filter_by_bahan.append(int(i))\n",
    "\n",
    "    for j in recipe_filter_by_bahan:\n",
    "        for i in range(1, len(recipe_filter_by_bahan)): \n",
    "            if int(float(recipe_dataset['kandungan_nutrisi'].iloc[int(recipe_filter_by_bahan[i])].replace(\"'\", \"\").replace(\"'\", \"\").strip().split(',')[1])) > int(float(recipe_dataset['kandungan_nutrisi'].iloc[int(recipe_filter_by_bahan[i - 1])].replace(\"'\", \"\").replace(\"'\", \"\").strip().split(',')[1])): \n",
    "                temp = recipe_filter_by_bahan[i-1]\n",
    "                recipe_filter_by_bahan[i -1] = recipe_filter_by_bahan[i]\n",
    "                recipe_filter_by_bahan[i] = temp\n",
    "    get_harga_bahan = []\n",
    "    get_bahan_recipe = []\n",
    "    for i in recipe_filter_by_bahan:\n",
    "        get_bahan_recipe.append(recipe_dataset['nama_bahan'].iloc[i].replace(\"'\", \"\").replace(\"'\", \"\").split(','))\n",
    "    all_satuan = []\n",
    "\n",
    "    for i in range(len(recipe_filter_by_bahan)): \n",
    "        temp  = recipe_dataset['satuan'].iloc[i].replace(\"'\", \"\").split(\",\")\n",
    "        all_satuan.append(temp)\n",
    "\n",
    "    for i in range(len(get_bahan_recipe)): \n",
    "        total = 0\n",
    "        for j in range(len(get_bahan_recipe[i])): \n",
    "            for k in range(len(data_harga_bahan)): \n",
    "                if str(data_harga_bahan['nama_bahan'].iloc[k]).replace(\" \", \"\") == get_bahan_recipe[i][j].replace(\" \", \"\") :\n",
    "                    if j < len(all_satuan[i]):\n",
    "                        if all_satuan[i][j] == \"ons\":   \n",
    "                            total += ((data_harga_bahan['harga'].iloc[k]) / 4)\n",
    "                        elif str(all_satuan[i][j]).replace(\" \", \"\") == 'sendokteh' or str(all_satuan[i][j]).replace(\" \", \"\") == 'sendokmakan':   \n",
    "                            total += ((data_harga_bahan['harga'].iloc[k]) / 10)\n",
    "                        elif str(all_satuan[i][j].replace(\" \", \"\")) == 'cangkir' or 'cangkir' in str(all_satuan[i][j].replace(\" \", \"\")):   \n",
    "                            total += ((data_harga_bahan['harga'].iloc[k]) / 2) \n",
    "                    else: \n",
    "                        total += (data_harga_bahan['harga'].iloc[k])\n",
    "        get_harga_bahan.append(total)\n",
    "\n",
    "\n",
    "    for i in range(len(get_harga_bahan)): \n",
    "        if get_harga_bahan[i] <= 50000: \n",
    "            continue\n",
    "        elif get_harga_bahan[i] <= 100000 and get_harga_bahan[i] >  50000: \n",
    "            get_harga_bahan[i] = get_harga_bahan[i] / 4\n",
    "        elif get_harga_bahan[i] > 100000 and get_harga_bahan[i] <= 200000: \n",
    "            get_harga_bahan[i] = get_harga_bahan[i] / 6\n",
    "        else: \n",
    "            get_harga_bahan[i] = get_harga_bahan[i] / 8\n",
    "        \n",
    "    final_recomend = []\n",
    "    for i in range(len(get_harga_bahan)): \n",
    "        temp = []\n",
    "        total  = 0\n",
    "        max_jump = int(len(get_harga_bahan) / (7 * jumlah_makan_sehari)) \n",
    "        jump = random.randint(a=1, b= max_jump)\n",
    "        for j in range(i, len(get_harga_bahan) - jump): \n",
    "            if int(total) <= int(budget):\n",
    "                total += (get_harga_bahan[j + jump] * (jumlah_dewasa + math.ceil(0.5 * jumlah_anak)))\n",
    "                temp.append(recipe_filter_by_bahan[j + jump])\n",
    "            else: \n",
    "                  temp = []\n",
    "            \n",
    "        if len(temp) >= 7 * jumlah_makan_sehari: \n",
    "            if temp not in final_recomend:\n",
    "                final_recomend.append(temp)\n",
    "    return final_recomend\n",
    "def get_recommender(bahan_yang_disukai, bahan_yang_tidak_disukai , pantangan_makan, budget, jumlah_makan_sehari, jumlah_dewasa, jumlah_anak, country_refrences_param): \n",
    "    pred =  retrain(country_refrences = country_refrences_param)\n",
    "    all = final_recomendation(prediction=pred, bahan_yang_disukai_param= bahan_yang_disukai, bahan_yang_tidak_disukai_param=bahan_yang_tidak_disukai, pantangan_makan_param= pantangan_makan, budget_param= budget, jumlah_makan_sehari_param=jumlah_makan_sehari, jumlah_anak_param = jumlah_anak,jumlah_dewasa_param=jumlah_dewasa)\n",
    "    return all\n",
    "\n",
    "# Unnamed: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "188/188 [==============================] - 10s 50ms/step - loss: 10.2020 - mse: 10.2020\n",
      "Epoch 2/2\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0475 - mse: 0.0475\n",
      "188/188 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "Y = get_recommender(bahan_yang_disukai = ['ayam', 'nasi'], bahan_yang_tidak_disukai =['keju'], pantangan_makan = ['babi'], budget =2000000, jumlah_makan_sehari = 3, jumlah_dewasa = 2, jumlah_anak = 2, country_refrences_param = ['Indonesian'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4039,\n",
       "  2561,\n",
       "  4992,\n",
       "  2531,\n",
       "  363,\n",
       "  2236,\n",
       "  991,\n",
       "  4646,\n",
       "  1500,\n",
       "  3879,\n",
       "  2218,\n",
       "  3598,\n",
       "  685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [5036,\n",
       "  993,\n",
       "  4039,\n",
       "  2561,\n",
       "  4992,\n",
       "  2531,\n",
       "  363,\n",
       "  2236,\n",
       "  991,\n",
       "  4646,\n",
       "  1500,\n",
       "  3879,\n",
       "  2218,\n",
       "  3598,\n",
       "  685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [363,\n",
       "  2236,\n",
       "  991,\n",
       "  4646,\n",
       "  1500,\n",
       "  3879,\n",
       "  2218,\n",
       "  3598,\n",
       "  685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [2236,\n",
       "  991,\n",
       "  4646,\n",
       "  1500,\n",
       "  3879,\n",
       "  2218,\n",
       "  3598,\n",
       "  685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [2531,\n",
       "  363,\n",
       "  2236,\n",
       "  991,\n",
       "  4646,\n",
       "  1500,\n",
       "  3879,\n",
       "  2218,\n",
       "  3598,\n",
       "  685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [991,\n",
       "  4646,\n",
       "  1500,\n",
       "  3879,\n",
       "  2218,\n",
       "  3598,\n",
       "  685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [1500,\n",
       "  3879,\n",
       "  2218,\n",
       "  3598,\n",
       "  685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [3598,\n",
       "  685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [685,\n",
       "  2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174],\n",
       " [2191,\n",
       "  2794,\n",
       "  728,\n",
       "  517,\n",
       "  3992,\n",
       "  2181,\n",
       "  4635,\n",
       "  4235,\n",
       "  5879,\n",
       "  4675,\n",
       "  2799,\n",
       "  4867,\n",
       "  2551,\n",
       "  3998,\n",
       "  4049,\n",
       "  628,\n",
       "  5597,\n",
       "  5232,\n",
       "  4956,\n",
       "  3635,\n",
       "  2174]]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
